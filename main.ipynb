{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gZOtgw9Oy9YX",
   "metadata": {
    "id": "gZOtgw9Oy9YX"
   },
   "source": [
    "# OCR Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c3c15",
   "metadata": {
    "id": "e92c3c15"
   },
   "source": [
    "# part 1: Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id"
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import difflib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import logging\n",
    "from skimage.morphology import (erosion, dilation, closing, opening)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "vK-ap1bbEenR",
   "metadata": {
    "id": "vK-ap1bbEenR"
   },
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "-nRPz4bQEdwp",
   "metadata": {
    "id": "-nRPz4bQEdwp"
   },
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "!wget https://www.orand.cl/orand_car/ORAND-CAR-2014.tar.gz\n",
    "\n",
    "# Step 2: Create a directory to extract the dataset\n",
    "os.makedirs(\"ORAND-CAR-2014\", exist_ok=True)\n",
    "\n",
    "# Step 3: Extract the dataset\n",
    "with tarfile.open(\"ORAND-CAR-2014.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall(path=\"ORAND-CAR-2014\")\n",
    "\n",
    "# Verify the extraction\n",
    "print(\"Files in ORAND-CAR-2014 directory:\")\n",
    "print(os.listdir(\"ORAND-CAR-2014\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e8637f1",
   "metadata": {
    "id": "4e8637f1"
   },
   "source": [
    "# preprocessing dataset\n",
    "Function to preprocess image (convert to grayscale and apply binary thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "id": "41b059040e10bad",
   "metadata": {
    "id": "41b059040e10bad"
   },
   "source": [
    "# element = np.array([[0, 0, 0, 0],\n",
    "#                     [0, 1, 1, 0],\n",
    "#                     [0, 1, 1, 0],\n",
    "#                     [0, 0, 0, 0]], np.uint8)\n",
    "\n",
    "element4 = np.array([[0, 0, 0, 0],\n",
    "                     [0, 1, 1, 0],\n",
    "                     [0, 1, 1, 0],\n",
    "                     [0, 0, 0, 0]])\n",
    "\n",
    "# element = np.array([[0, 0, 0, 0, 0],\n",
    "#                     [0, 1, 1, 1, 0],\n",
    "#                     [0, 1, 1, 1, 0],\n",
    "#                     [0, 1, 1, 1, 0],\n",
    "#                     [0, 0, 0, 0, 0]], np.uint8)\n",
    "\n",
    "element5 = np.array([[0, 0, 0, 0, 0],\n",
    "                     [0, 0, 1, 0, 0],\n",
    "                     [0, 1, 1, 1, 0],\n",
    "                     [0, 0, 1, 0, 0],\n",
    "                     [0, 0, 0, 0, 0]])\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    # binary_img = opening(binary_img, element5)\n",
    "    # binary_img = erosion(binary_img, element4)\n",
    "    # binary_img = dilation(binary_img, element2)\n",
    "    # binary_img = cv2.morphologyEx(binary_img, cv2.MORPH_HITMISS, element)\n",
    "    return img, binary_img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff9fb52c",
   "metadata": {
    "id": "ff9fb52c"
   },
   "source": [
    "# Displaying the input images and binary images"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c869e5024ebd8fd",
   "metadata": {
    "id": "2c869e5024ebd8fd"
   },
   "source": [
    "def display_image(img, binary_img, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Original {title}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(binary_img, cmap='gray')\n",
    "    plt.title(f\"Binary {title}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e0eb85a2",
   "metadata": {
    "id": "e0eb85a2"
   },
   "source": [
    "# Function to find and draw contours"
   ]
  },
  {
   "cell_type": "code",
   "id": "89e9da79588fc7ee",
   "metadata": {
    "id": "89e9da79588fc7ee"
   },
   "source": [
    "def segment_characters(binary_img, max_width=10, max_height=10):\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_contours = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "        if w > max_width and h > max_height:\n",
    "            filtered_contours.append(contour)\n",
    "\n",
    "    filtered_contours = sorted(filtered_contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    return filtered_contours"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0d3f0c32",
   "metadata": {
    "id": "0d3f0c32"
   },
   "source": [
    "# Function to display contours"
   ]
  },
  {
   "cell_type": "code",
   "id": "2bf1b9e190cb584e",
   "metadata": {
    "id": "2bf1b9e190cb584e"
   },
   "source": [
    "def display_contours(img, contours, title):\n",
    "    img_with_contours = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(img_with_contours, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(img_with_contours)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e27cbeb5",
   "metadata": {
    "id": "e27cbeb5"
   },
   "source": [
    "# Samples of segmented charactests"
   ]
  },
  {
   "cell_type": "code",
   "id": "c260bf50e4f9f09f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "id": "c260bf50e4f9f09f",
    "outputId": "4920dde4-2b75-43ea-ca2c-f39d556a1548"
   },
   "source": [
    "image_paths = ['ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_test_images/a_car_007000.png',\n",
    "               \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_test_images/a_car_007001.png\",\n",
    "               \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_test_images/a_car_007002.png\"]\n",
    "\n",
    "# image_paths = ['ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_train_images/a_car_000155.png',\n",
    "#                \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_train_images/a_car_000156.png\",\n",
    "#                \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_train_images/a_car_000157.png\"]\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    original, binary = preprocess_image(image_path)\n",
    "    # display_image(original, binary, Image {i + 1})\n",
    "    contours = segment_characters(binary)\n",
    "    display_contours(binary, contours, f\"Segmented Characters in Image {i + 1}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90ccea2a",
   "metadata": {
    "id": "90ccea2a"
   },
   "source": [
    "# Training a MNIST model"
   ]
  },
  {
   "cell_type": "code",
   "id": "820d6c96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "820d6c96",
    "outputId": "6c0a7276-ef9b-4028-a97c-2db85791fe21"
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=32)\n",
    "model.save('mnist_cnn_model.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "82f50f3c",
   "metadata": {
    "id": "82f50f3c"
   },
   "source": [
    "# preprocess character image for prediction"
   ]
  },
  {
   "cell_type": "code",
   "id": "78988199",
   "metadata": {
    "id": "78988199"
   },
   "source": [
    "def preprocess_char_img(char_img):\n",
    "    char_img = cv2.resize(char_img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    char_img = char_img.astype('float32') / 255.0\n",
    "    char_img = np.expand_dims(char_img, axis=-1)\n",
    "    char_img = np.expand_dims(char_img, axis=0)\n",
    "    return char_img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf270abb",
   "metadata": {
    "id": "bf270abb"
   },
   "source": [
    "# Function to recognize characters"
   ]
  },
  {
   "cell_type": "code",
   "id": "6e688125",
   "metadata": {
    "id": "6e688125"
   },
   "source": [
    "def recognize_characters(model, binary_img, contours):\n",
    "    recognized_digits = \"\"\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        char_img = binary_img[y:y + h, x:x + w]\n",
    "        char_img = preprocess_char_img(char_img)\n",
    "        prediction = model.predict(char_img)\n",
    "        recognized_digit = np.argmax(prediction)\n",
    "        recognized_digits = recognized_digits + str(recognized_digit)\n",
    "    return recognized_digits"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae64fde9",
   "metadata": {
    "id": "ae64fde9"
   },
   "source": [
    "# Testing MNIST model on ORAND-CAR-2014 CAR-A test dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "1038dc28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1038dc28",
    "outputId": "01710d7c-5e0d-47cb-a7a1-3d4bf131a699"
   },
   "source": [
    "model = load_model('mnist_cnn_model.h5')\n",
    "\n",
    "image_folder = 'ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_test_images'\n",
    "image_gt = \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_test_gt.txt\"\n",
    "with open(image_gt, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "file_names = []\n",
    "labels = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    name, num = line.split()\n",
    "    file_names.append(name)\n",
    "    labels.append(num)\n",
    "\n",
    "sim = 0.0\n",
    "equality = 0\n",
    "for i, file in enumerate(file_names):\n",
    "    image_path = os.path.join(image_folder, file)\n",
    "    original, binary = preprocess_image(image_path)\n",
    "    contours = segment_characters(binary)\n",
    "    recognized_digits = recognize_characters(model, binary, contours)\n",
    "    print(f\"Recognized digits in {file}: {recognized_digits} {labels[i]}\")\n",
    "    similarity = difflib.SequenceMatcher(None, recognized_digits, labels[i]).ratio()\n",
    "    sim += similarity\n",
    "    if (int(recognized_digits) == int(labels[i])):\n",
    "        # print(f\"Recognized digits in {file}: {recognized_digits} {labels[i]}\")\n",
    "        equality += 1\n",
    "print(sim, \" out of \", len(labels), \"are similar.\")\n",
    "print(\"Similarity accuracy: \", sim / float(len(labels)))\n",
    "print(equality, \" out of \", len(labels), \"are equal.\")\n",
    "print(\"Equality accuracy  : \", float(equality) / float(len(labels)))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ac7d889b",
   "metadata": {
    "id": "ac7d889b"
   },
   "source": [
    "# part 2: Using CRNN"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b194c24",
   "metadata": {
    "id": "7b194c24"
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers, Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, \\\n",
    "    BatchNormalization, Dropout, GRU, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "import tensorflow.keras.backend as K\n",
    "import difflib"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f9c25163",
   "metadata": {
    "id": "f9c25163"
   },
   "source": [
    "# preprocess image\n",
    "In preprocess_image_crop, The width and height are **cropped** if they are greater than 256 and 64 respectively.<br><br>\n",
    "in preprocess_image_resize, The width and height are **resized** if they are greater than 256 and 64 respectively."
   ]
  },
  {
   "cell_type": "code",
   "id": "b1a4da53",
   "metadata": {
    "id": "b1a4da53"
   },
   "source": [
    "def preprocess_image_crop(image_path, big_w, big_h, w_img, h_img):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    (h, w) = img.shape\n",
    "\n",
    "    final_img = np.ones([64, 256]) * 255  # black white image\n",
    "    # crop\n",
    "    if w > 256:\n",
    "        if w > big_w:\n",
    "            w_img = img\n",
    "            big_w = w\n",
    "        img = img[:, :256]\n",
    "\n",
    "    if h > 64:\n",
    "        if h > big_h:\n",
    "            h_img = img\n",
    "            big_h = h\n",
    "        img = img[:64, :]\n",
    "\n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE), big_w, big_h, w_img, h_img\n",
    "\n",
    "\n",
    "def preprocess_image_resize(image_path, big_w, big_h, w_img, h_img):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    (h, w) = img.shape\n",
    "\n",
    "    final_img = np.ones([64, 256]) * 255  # black white image\n",
    "    # crop\n",
    "    if w > 256:\n",
    "        img = img = cv2.resize(img, (256, h))\n",
    "        if w > big_w:\n",
    "            w_img = img\n",
    "            big_w = w\n",
    "        w = 256\n",
    "\n",
    "    if h > 64:\n",
    "        img = img = cv2.resize(img, (w, 64))\n",
    "        if h > big_h:\n",
    "            h_img = img\n",
    "            big_h = h\n",
    "        h = 64\n",
    "\n",
    "    # print(h, w)\n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE), big_w, big_h, w_img, h_img"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8fd1cc9d",
   "metadata": {
    "id": "8fd1cc9d"
   },
   "source": [
    "# Function to read file names and labels"
   ]
  },
  {
   "cell_type": "code",
   "id": "17f5bfcf",
   "metadata": {
    "id": "17f5bfcf"
   },
   "source": [
    "def read_labels(image_folder, image_gt):\n",
    "    big_w = 0.0\n",
    "    big_h = 0.0\n",
    "    path = './ORAND-CAR-2014/CAR-A/a_train_images/a_car_000154.png'\n",
    "    w_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    h_img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    with open(image_gt, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    file_names = []\n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        name, num = line.split()\n",
    "        file_names.append(name)\n",
    "        labels.append(num)\n",
    "\n",
    "    images = []\n",
    "    for file in file_names:\n",
    "        image_path = os.path.join(image_folder, file)\n",
    "        # img, big_w, big_h, w_img, h_img = preprocess_image_crop(image_path, big_w, big_h, w_img, h_img)\n",
    "        img, big_w, big_h, w_img, h_img = preprocess_image_resize(image_path, big_w, big_h, w_img, h_img)\n",
    "        images.append(img)\n",
    "\n",
    "    plt.imshow(w_img, cmap='gray')\n",
    "    plt.show()\n",
    "    print(big_w)\n",
    "    plt.imshow(h_img, cmap='gray')\n",
    "    plt.show()\n",
    "    print(big_h)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ded38767",
   "metadata": {
    "id": "ded38767"
   },
   "source": [
    "# Loading the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "id": "itV9iLanUFxB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "itV9iLanUFxB",
    "outputId": "31632dd4-0a0d-4ead-b5e2-6f9093ac6b57"
   },
   "source": [
    "train_image_folder = 'ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_train_images'\n",
    "train_image_gt = \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_train_gt.txt\"\n",
    "val_image_folder = 'ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_test_images'\n",
    "val_image_gt = \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-A/a_test_gt.txt\"\n",
    "\n",
    "train_image_folder2 = 'ORAND-CAR-2014/ORAND-CAR-2014/CAR-B/b_train_images'\n",
    "train_image_gt2 = \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-B/b_train_gt.txt\"\n",
    "test_image_folder = 'ORAND-CAR-2014/ORAND-CAR-2014/CAR-B/b_test_images'\n",
    "test_image_gt = \"ORAND-CAR-2014/ORAND-CAR-2014/CAR-B/b_test_gt.txt\"\n",
    "\n",
    "train_images1, train_labels1 = read_labels(train_image_folder, train_image_gt)\n",
    "val_images, val_labels = read_labels(val_image_folder, val_image_gt)\n",
    "\n",
    "train_images2, train_labels2 = read_labels(train_image_folder2, train_image_gt2)\n",
    "test_images, test_labels = read_labels(test_image_folder, test_image_gt)\n",
    "\n",
    "train_images = np.concatenate([train_images1, train_images2])\n",
    "train_labels = np.append(train_labels1, train_labels2)\n",
    "print(len(train_images1), len(train_images2), len(train_images), len(train_labels))\n",
    "\n",
    "train_size = len(train_images)\n",
    "valid_size = len(val_images)\n",
    "test_size = len(test_images)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5d4a1ca2",
   "metadata": {
    "id": "5d4a1ca2"
   },
   "source": [
    "# Preparing the labels for CTC Loss"
   ]
  },
  {
   "cell_type": "code",
   "id": "e4ca391a",
   "metadata": {
    "id": "e4ca391a"
   },
   "source": [
    "alphabets = u\"0123456789\"\n",
    "max_str_len = 8  # max length of input labels\n",
    "num_of_characters = len(alphabets) + 1  # +1 for ctc pseudo blank(epsilon)\n",
    "num_of_timestamps = 64  # max length of predicted labels\n",
    "\n",
    "\n",
    "def label_to_num(label):\n",
    "    label_num = []\n",
    "    for ch in label:\n",
    "        label_num.append(alphabets.find(ch))\n",
    "        #find() method returns the lowest index of the substring if it is found in given string otherwise -1\n",
    "\n",
    "    return np.array(label_num)\n",
    "\n",
    "\n",
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret += alphabets[ch]\n",
    "    return ret"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d6693fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d6693fc",
    "outputId": "fb485cfb-34a1-47f1-a2a6-d82046b84228"
   },
   "source": [
    "train_y = np.ones([train_size, max_str_len]) * -1\n",
    "train_label_len = np.zeros([train_size, 1])\n",
    "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps - 2)\n",
    "train_output = np.zeros([train_size])\n",
    "\n",
    "for i in range(train_size):\n",
    "    train_label_len[i] = len(train_labels[i])\n",
    "    train_y[i, 0:len(train_labels[i])] = label_to_num(train_labels[i])\n",
    "\n",
    "valid_y = np.ones([valid_size, max_str_len]) * -1\n",
    "valid_label_len = np.zeros([valid_size, 1])\n",
    "valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps - 2)\n",
    "valid_output = np.zeros([valid_size])\n",
    "\n",
    "for i in range(valid_size):\n",
    "    valid_label_len[i] = len(val_labels[i])\n",
    "    valid_y[i, 0:len(val_labels[i])] = label_to_num(val_labels[i])\n",
    "\n",
    "print('True label : ', train_labels[100], '\\ntrain_y : ', train_y[100], '\\ntrain_label_len : ', train_label_len[100],\n",
    "      '\\ntrain_input_len : ', train_input_len[100])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "65226101",
   "metadata": {
    "id": "65226101"
   },
   "source": [
    "# Build the model (Multiple option choose one and run)\n",
    "Chatgpt model (problem: low Accuracy, loss:10)"
   ]
  },
  {
   "cell_type": "code",
   "id": "iSdZH17IxmMA",
   "metadata": {
    "id": "iSdZH17IxmMA"
   },
   "source": [
    "input_shape = (256, 64, 1)\n",
    "input_data = Input(shape=input_shape, name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), activation='relu', padding='same')(input_data)\n",
    "inner = MaxPooling2D((2, 2))(inner)\n",
    "inner = Conv2D(64, (3, 3), activation='relu', padding='same')(inner)\n",
    "inner = MaxPooling2D((2, 2))(inner)\n",
    "inner = Conv2D(128, (3, 3), activation='relu', padding='same')(inner)\n",
    "inner = MaxPooling2D((2, 2))(inner)\n",
    "inner = Conv2D(256, (3, 3), activation='relu', padding='same')(inner)\n",
    "inner = MaxPooling2D((2, 2))(inner)\n",
    "inner = Reshape((-1, inner.shape[-1]))(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(layers.LSTM(128, return_sequences=True))(inner)\n",
    "inner = Bidirectional(layers.LSTM(128, return_sequences=True))(inner)\n",
    "inner = layers.Dropout(0.5)(inner)\n",
    "## OUTPUT\n",
    "y_pred = Dense(num_of_characters, activation='softmax')(inner)\n",
    "\n",
    "model = Model(input_data, y_pred)\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "XZ7cqgmVyLH7",
   "metadata": {
    "id": "XZ7cqgmVyLH7"
   },
   "source": [
    "Zhan, H., Wang, Q., Lu, Y., \"Handwritten digit string recognition by combination of residual network and RNN-CTC\" 2017 (problem: too much proccess & too slow)"
   ]
  },
  {
   "cell_type": "code",
   "id": "18f55a47",
   "metadata": {
    "id": "18f55a47"
   },
   "source": [
    "input_shape = (256, 64, 1)\n",
    "input_data = Input(shape=input_shape, name='input')\n",
    "\n",
    "x = layers.Conv2D(64, (5, 5), strides=(1, 1), padding='same', activation='relu')(input_data)\n",
    "x = layers.MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "# Block 1\n",
    "x1 = layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "x2 = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x2 = layers.UpSampling2D((2, 2))(x2)  # Upsample to match the shape of x1\n",
    "x = layers.add([x1, x2])\n",
    "\n",
    "# Block 2\n",
    "x1 = layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "x2 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x2 = layers.UpSampling2D((2, 2))(x2)  # Upsample to match the shape of x1\n",
    "x = layers.add([x1, x2])\n",
    "\n",
    "# Block 3\n",
    "x1 = layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "x2 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x2 = layers.UpSampling2D((2, 2))(x2)  # Upsample to match the shape of x1\n",
    "x = layers.add([x1, x2])\n",
    "\n",
    "# Block 4\n",
    "x1 = layers.Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "x2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x2 = layers.UpSampling2D((2, 2))(x2)  # Upsample to match the shape of x1\n",
    "x = layers.add([x1, x2])\n",
    "\n",
    "# Block 5\n",
    "x = layers.Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "# Permute the blob to fit LSTM\n",
    "x = layers.Permute((2, 1, 3))(x)\n",
    "shape = x.shape\n",
    "x = layers.Reshape(target_shape=(shape[1], shape[2] * shape[3]))(x)\n",
    "\n",
    "# Reverse layer\n",
    "x = layers.Lambda(lambda t: tf.reverse(t, axis=[1]))(x)\n",
    "\n",
    "# LSTM layers\n",
    "x = layers.Bidirectional(layers.LSTM(100, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(100, return_sequences=True))(x)\n",
    "\n",
    "# Reverse layer\n",
    "x = layers.Lambda(lambda t: tf.reverse(t, axis=[1]))(x)\n",
    "x = layers.Dense(100, activation='relu')(x)\n",
    "y_pred = layers.Dense(11, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_data, y_pred)\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "L_-K9MFP51Ag",
   "metadata": {
    "id": "L_-K9MFP51Ag"
   },
   "source": [
    "Shi, B., Bai, X., & Yao, C., \"An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition\" 2017"
   ]
  },
  {
   "cell_type": "code",
   "id": "c-IR4xg41VeG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "id": "c-IR4xg41VeG",
    "outputId": "cd17535e-2a58-4b82-b7c0-e1379a1e3974"
   },
   "source": [
    "input_shape = (256, 64, 1)\n",
    "input_data = Input(shape=input_shape, name='input')\n",
    "# Convolutional layers\n",
    "x = Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, padding='same')(input_data)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((1, 2), padding='same')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((1, 2), padding='same')(x)\n",
    "x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n",
    "\n",
    "# Map to sequence\n",
    "x = Reshape((-1, 512))(x)\n",
    "\n",
    "# Recurrent layers\n",
    "x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "\n",
    "# Output layer\n",
    "y_pred = Dense(num_of_characters, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_data, y_pred)\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2QKv2gGkyVP6",
   "metadata": {
    "id": "2QKv2gGkyVP6"
   },
   "source": [
    "\n",
    "Sagar-modelling / Handwriting_Recognition_CRNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "id": "6aKBgsw-x0_1",
   "metadata": {
    "id": "6aKBgsw-x0_1"
   },
   "source": [
    "input_shape = (256, 64, 1)\n",
    "input_data = Input(shape=input_shape, name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "# CNN to RNN\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name='lstm2')(inner)\n",
    "\n",
    "## OUTPUT\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal', name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(input_data, y_pred)\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12e85c63",
   "metadata": {
    "id": "12e85c63"
   },
   "source": [
    "# the ctc loss function"
   ]
  },
  {
   "cell_type": "code",
   "id": "ddcb4151",
   "metadata": {
    "id": "ddcb4151"
   },
   "source": [
    "# def scheduler(epoch, lr):\n",
    "#     if epoch < 50:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         return 0.01\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)\n",
    "\n",
    "file_path_best = \"RNN_model.keras\"\n",
    "op = Adam()  # ---------------------------------------------------------------------------------------------\n",
    "# lr_cb = LearningRateScheduler(scheduler)\n",
    "ls = {'ctc': lambda y_true, y_pred: y_pred}\n",
    "model_final.compile(loss=ls, optimizer=op)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=file_path_best,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          patience=10\n",
    "                          )\n",
    "\n",
    "callbacks_list = [earlystop, checkpoint]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "Ki6mFmrsUwip",
   "metadata": {
    "id": "Ki6mFmrsUwip"
   },
   "source": [
    "# Training model and plotting the train and validation state loss in each epoch"
   ]
  },
  {
   "cell_type": "code",
   "id": "8e0a70a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e0a70a0",
    "outputId": "6a0a7a08-eb4a-49eb-fd8d-76c57b1231db"
   },
   "source": [
    "history = model_final.fit(x=[train_images, train_y, train_input_len, train_label_len],\n",
    "                          y=train_output,\n",
    "                          validation_data=([val_images, valid_y, valid_input_len, valid_label_len], valid_output),\n",
    "                          callbacks=callbacks_list,\n",
    "                          verbose=1,\n",
    "                          epochs=300,\n",
    "                          batch_size=64,\n",
    "                          shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "DMLoIjCBUk-q",
   "metadata": {
    "id": "DMLoIjCBUk-q"
   },
   "source": [
    "model.load_weights('RNN_model.keras')\n",
    "preds = model.predict(test_images)\n",
    "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0]) * preds.shape[1],\n",
    "                                   greedy=True)[0][0])\n",
    "\n",
    "prediction = []\n",
    "for i in range(test_size):\n",
    "    prediction.append(num_to_label(decoded[i]))\n",
    "\n",
    "y_true = test_labels\n",
    "sim = 0\n",
    "total_char = 0\n",
    "equality = 0\n",
    "\n",
    "for i in range(test_size):\n",
    "    pr = prediction[i]\n",
    "    tr = y_true[i]\n",
    "    total_char += len(tr)\n",
    "\n",
    "    similarity = difflib.SequenceMatcher(None, pr, tr).ratio()\n",
    "    sim += similarity\n",
    "\n",
    "    if (pr == tr):\n",
    "        equality += 1\n",
    "\n",
    "print('Similarity accuracy:  %.2f%%' % (sim * 100 / test_size))\n",
    "print('Equality accuracy  :  %.2f%%' % (equality * 100 / test_size))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "mi_P_6QO8vGM",
   "metadata": {
    "id": "mi_P_6QO8vGM"
   },
   "source": [
    "# How difflib.SequenceMatcher works"
   ]
  },
  {
   "cell_type": "code",
   "id": "QNKCNIeH8uia",
   "metadata": {
    "id": "QNKCNIeH8uia"
   },
   "source": [
    "str1 = \"kitten\"\n",
    "str2 = \"sitting\"\n",
    "\n",
    "similarity = difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "print(\"similarity: \", similarity)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
